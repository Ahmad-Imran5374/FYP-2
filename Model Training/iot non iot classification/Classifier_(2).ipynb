{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Excel file\n",
        "xlsx_path = 'modeldata.xlsx'  # Change to your actual filename\n",
        "df = pd.read_excel(xlsx_path)\n",
        "\n",
        "# Save as CSV\n",
        "csv_path = xlsx_path.replace('.xlsx', '.csv')\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Converted and saved to: {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOTulqsbCPxN",
        "outputId": "8d0eebca-d50e-4775-d6b8-9426a8cddfcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted and saved to: modeldata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('classdata.csv')\n",
        "\n",
        "# Add or update the 'Label' column based on 'Src IP'\n",
        "df['Label'] = df['Src IP'].apply(lambda ip: 'IoT Device' if ip == '192.168.219.59' or ip == '192.168.195.59' or ip == '10.101.101.40' or ip == '192.168.190.59' else 'Non-IoT Device')\n",
        "\n",
        "# Save changes to the same file (overwrite)\n",
        "df.to_csv('classdata.csv', index=False)\n",
        "\n",
        "print(\"Label column updated in 'bothdata.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IyhfMrGCTSZ",
        "outputId": "cd467f6d-bd26-4269-96c4-c8e878fb75f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label column updated in 'bothdata.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# === UTILITIES ===\n",
        "def clean_df(df):\n",
        "    # Replace infinite values with NaN, then fill NaNs with 0 (or you could df.dropna())\n",
        "    return df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "# === TRAINING ===\n",
        "train_df = pd.read_csv('classdata.csv')\n",
        "\n",
        "# Drop IP and Port columns\n",
        "drop_cols = ['Src IP', 'Dst IP', 'Src Port', 'Dst Port']\n",
        "train_df = train_df.drop(columns=[c for c in drop_cols if c in train_df.columns])\n",
        "\n",
        "# Features and labels\n",
        "X = train_df.drop('Label', axis=1)\n",
        "y = train_df['Label']\n",
        "\n",
        "# One-hot encoding\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Clean any infinities / NaNs\n",
        "X_encoded = clean_df(X_encoded)\n",
        "\n",
        "# Label encoding\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# XGBoost classifier\n",
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "val_preds = model.predict(X_val)\n",
        "print(\"Validation Report:\\n\",\n",
        "      classification_report(y_val, val_preds, target_names=le.classes_))\n",
        "\n",
        "# === PREDICTION ===\n",
        "test_path = 'malicious_only.csv'\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# Clean and align test features\n",
        "test_df_clean = test_df.drop(columns=[c for c in drop_cols if c in test_df.columns], errors='ignore')\n",
        "test_encoded = pd.get_dummies(test_df_clean)\n",
        "\n",
        "# Ensure same columns as training\n",
        "test_encoded = test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
        "\n",
        "# Clean infinities / NaNs in test set\n",
        "test_encoded = clean_df(test_encoded)\n",
        "\n",
        "# Predict classes and probabilities\n",
        "pred_probs = model.predict_proba(test_encoded)\n",
        "pred_classes = model.predict(test_encoded)\n",
        "\n",
        "# Decode labels and attach confidence\n",
        "test_df['Label'] = le.inverse_transform(pred_classes)\n",
        "test_df['Confidence'] = pred_probs.max(axis=1)\n",
        "\n",
        "# Filter: keep only high-confidence rows\n",
        "filtered_df = test_df[test_df['Confidence'] >= 0.967].copy()\n",
        "\n",
        "# Count IoT vs Non-IoT\n",
        "counts = filtered_df['Label'].value_counts()\n",
        "iot_count = counts.get('IoT', 0)\n",
        "non_iot_count = counts.sum() - iot_count\n",
        "\n",
        "print(f\"Total high-confidence packets: {len(filtered_df)}\")\n",
        "print(f\"IoT packets: {iot_count}\")\n",
        "print(f\"Non-IoT packets: {non_iot_count}\")\n",
        "\n",
        "# Save filtered predictions\n",
        "filtered_df.to_csv(test_path, index=False)\n",
        "print(f\"Filtered predictions (confidence ≥ 0.967) saved to: {test_path}\")\n",
        "filtered_df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "IcIxxQ1R3N3K",
        "outputId": "fa0f9645-3a36-419e-8347-0627b39ae5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:22:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    IoT Device       1.00      1.00      1.00       307\n",
            "Non-IoT Device       1.00      1.00      1.00       105\n",
            "\n",
            "      accuracy                           1.00       412\n",
            "     macro avg       1.00      1.00      1.00       412\n",
            "  weighted avg       1.00      1.00      1.00       412\n",
            "\n",
            "Total high-confidence packets: 1025\n",
            "IoT packets: 0\n",
            "Non-IoT packets: 1025\n",
            "Filtered predictions (confidence ≥ 0.967) saved to: malicious_only.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "IoT Device        1023\n",
              "Non-IoT Device       2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>IoT Device</th>\n",
              "      <td>1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Non-IoT Device</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib==1.4.2\n",
        "!pip install numpy==1.24.4\n",
        "!pip install pandas==2.0.3\n",
        "!pip install scikit-learn==1.3.2\n",
        "!pip install xgboost==2.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZbV8rKL-i9",
        "outputId": "978e49d1-84ec-482b-c919-2d31c3fcf1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\n",
            "Requirement already satisfied: xgboost==2.1.4 in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (1.24.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.1.4) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "# Suppress XGBoost warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Function to replace infinite values with NaN (replaces the lambda)\n",
        "def replace_inf_with_nan(x):\n",
        "    return np.where(np.isinf(x), np.nan, x)\n",
        "\n",
        "# Load labeled training data\n",
        "df = pd.read_csv('classdata.csv')\n",
        "\n",
        "# Drop unwanted columns\n",
        "X = df.drop(['Label', 'Flow ID', 'Timestamp', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port'], axis=1, errors='ignore')\n",
        "y_raw = df['Label']\n",
        "\n",
        "# Split data\n",
        "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
        "    X, y_raw, test_size=0.20, stratify=y_raw, random_state=42\n",
        ")\n",
        "\n",
        "# Encode string labels to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train_raw)\n",
        "y_test = label_encoder.transform(y_test_raw)\n",
        "\n",
        "# Set XGBoost objective\n",
        "num_classes = len(label_encoder.classes_)\n",
        "if num_classes == 2:\n",
        "    objective = 'binary:logistic'\n",
        "    eval_metric = 'logloss'\n",
        "else:\n",
        "    objective = 'multi:softprob'\n",
        "    eval_metric = 'mlogloss'\n",
        "\n",
        "# Define XGBoost parameters\n",
        "xgb_params = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.1,\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': eval_metric,\n",
        "    'objective': objective,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "if num_classes > 2:\n",
        "    xgb_params['num_class'] = num_classes\n",
        "\n",
        "# Preprocessing pipeline\n",
        "cat_cols = ['Protocol']\n",
        "num_cols = [c for c in X_train_raw.columns if c not in cat_cols]\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
        "    ('num', Pipeline([\n",
        "        ('clip', FunctionTransformer(replace_inf_with_nan, validate=False)),\n",
        "        ('impute', SimpleImputer(strategy='median'))\n",
        "    ]), num_cols)\n",
        "])\n",
        "\n",
        "# Build training pipeline\n",
        "train_pipeline = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('xgb', XGBClassifier(**xgb_params))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "train_pipeline.fit(X_train_raw, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(train_pipeline, 'classifier.pkl')\n",
        "print(\"✅ Trained model saved to 'classifier.pkl'\")\n",
        "\n",
        "# ───────────────────────────────────────────────────────────\n",
        "# Load model and predict on test.csv\n",
        "# ───────────────────────────────────────────────────────────\n",
        "print(\"\\n🔄 Loading model for predictions...\")\n",
        "loaded_pipeline = joblib.load('classifier.pkl')\n",
        "\n",
        "# Evaluate loaded model on hold-out test set\n",
        "y_pred = loaded_pipeline.predict(X_test_raw)\n",
        "print(\"\\n📊 Evaluation on Test Set:\")\n",
        "print(\"Number of features used for training:\", loaded_pipeline.named_steps['pre'].transform(X_train_raw).shape[1])\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv('iotdata.csv')\n",
        "test_features = test_df.drop(['Flow ID', 'Timestamp', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Label'], axis=1, errors='ignore')\n",
        "\n",
        "# Predict using loaded model\n",
        "test_pred_numeric = loaded_pipeline.predict(test_features)\n",
        "test_pred_label = label_encoder.inverse_transform(test_pred_numeric)\n",
        "test_proba = loaded_pipeline.predict_proba(test_features).max(axis=1)\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "test_df['Predicted_Label'] = test_pred_label\n",
        "test_df['Confidence'] = test_proba\n",
        "\n",
        "# Filter low-confidence predictions\n",
        "filtered_df = test_df[test_df['Confidence'] >= 0.80]\n",
        "\n",
        "# Summary\n",
        "print(\"\\n📈 Prediction Summary (Confidence ≥ 0.65):\")\n",
        "print(filtered_df['Predicted_Label'].value_counts())\n",
        "print(\"\\nPrediction Proportions (%):\")\n",
        "print((filtered_df['Predicted_Label'].value_counts(normalize=True) * 100).round(2))\n",
        "\n",
        "# Save predictions\n",
        "filtered_df.to_csv('iotdata.csv', index=False)\n",
        "print(f\"\\n✅ Filtered predictions saved to 'iotdata.csv' (kept {len(filtered_df)} of {len(test_df)} rows)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UyGSFj0hmnl",
        "outputId": "16960b7d-67b2-4725-edf1-32a5bca9dd6a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Trained model saved to 'attack.pkl'\n",
            "\n",
            "🔄 Loading model for predictions...\n",
            "\n",
            "📊 Evaluation on Test Set:\n",
            "Number of features used for training: 79\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    IoT Device       1.00      1.00      1.00       682\n",
            "Non-IoT Device       1.00      1.00      1.00       301\n",
            "\n",
            "      accuracy                           1.00       983\n",
            "     macro avg       1.00      1.00      1.00       983\n",
            "  weighted avg       1.00      1.00      1.00       983\n",
            "\n",
            "Confusion Matrix:\n",
            " [[681   1]\n",
            " [  1 300]]\n",
            "Accuracy: 0.9979654120040692\n",
            "\n",
            "📈 Prediction Summary (Confidence ≥ 0.65):\n",
            "Predicted_Label\n",
            "Non-IoT Device    579\n",
            "IoT Device         48\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Prediction Proportions (%):\n",
            "Predicted_Label\n",
            "Non-IoT Device    92.34\n",
            "IoT Device         7.66\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "✅ Filtered predictions saved to 'other_data_labeled.csv' (kept 627 of 631 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# ─── 1) Load your trained classifier pipeline ───────────────────\n",
        "pipeline = joblib.load('classifier.pkl')\n",
        "\n",
        "# ─── 2) Load & preprocess the new data ─────────────────────────\n",
        "df = pd.read_csv('iotdata.csv')\n",
        "drop_cols = ['Flow ID','Timestamp','Src IP','Dst IP','Src Port','Dst Port','Label']\n",
        "X_new = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "# ─── 3) Run predictions ─────────────────────────────────────────\n",
        "pred_numeric = pipeline.predict(X_new)          # numeric class codes\n",
        "probs        = pipeline.predict_proba(X_new)    # probabilities\n",
        "\n",
        "# ─── 4) Attach numeric labels & confidences ────────────────────\n",
        "df['Predicted_Label'] = pred_numeric\n",
        "df['Confidence']      = np.max(probs, axis=1)\n",
        "\n",
        "# ─── 5) (Optional) filter low-confidence predictions ───────────\n",
        "threshold = 0.80\n",
        "filtered_df = df[df['Confidence'] >= threshold]\n",
        "\n",
        "# ─── 6) Save the results ───────────────────────────────────────\n",
        "output_file = 'noiotdata.csv'\n",
        "filtered_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✅ Saved {len(filtered_df)}/{len(df)} rows to {output_file}\")\n",
        "print(\"Label counts:\\n\", filtered_df['Predicted_Label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ6_SADTlZ-U",
        "outputId": "13b39b4d-9049-4f61-f44f-801f46f797dd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 214/214 rows to noiotdata.csv\n",
            "Label counts:\n",
            " Predicted_Label\n",
            "0    198\n",
            "1     16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}